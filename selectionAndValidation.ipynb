{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.15"
    },
    "colab": {
      "name": "Lab5MollyCreagar.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju__ZG3RvXlG",
        "outputId": "4b53a2f1-98c4-4ee8-ec7c-99faf5bb6ebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        }
      },
      "source": [
        "#This lab uses the hitters.csv file to demonstrate forward selection, backward elimination, stepwise selection\n",
        "#and different validation methods. Lab tasks done in both R and Python\n",
        "import rpy2.rinterface\n",
        "%load_ext rpy2.ipython\n",
        "import os\n",
        "import sys\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from patsy import dmatrices\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold\n",
        "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
        "\n",
        "##In Python\n",
        "##Read in the data\n",
        "hitters = pd.read_csv('hitters.csv')\n",
        "n = len(hitters['Salary'])\n",
        "##a\n",
        "expVars = hitters.drop(labels = \"Salary\", axis = 1)\n",
        "expVars = \"+\".join(expVars.columns)\n",
        "\n",
        "y, X = dmatrices('Salary ~' + expVars, hitters, return_type='dataframe')\n",
        "vif = pd.DataFrame()\n",
        "vif[\"VIF Factor\"] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
        "vif[\"variable\"] = X.columns\n",
        "vif"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    VIF Factor        variable\n",
              "0    21.762082       Intercept\n",
              "1     4.134115     League[T.N]\n",
              "2     1.075398   Division[T.W]\n",
              "3     4.099063  NewLeague[T.N]\n",
              "4    22.944366           AtBat\n",
              "5    30.281255            Hits\n",
              "6     7.758668           HmRun\n",
              "7    15.246418            Runs\n",
              "8    11.921715             RBI\n",
              "9     4.148712           Walks\n",
              "10    9.313280           Years\n",
              "11  251.561160          CAtBat\n",
              "12  502.954289           CHits\n",
              "13   46.488462          CHmRun\n",
              "14  162.520810           CRuns\n",
              "15  131.965858            CRBI\n",
              "16   19.744105          CWalks\n",
              "17    1.236317         PutOuts\n",
              "18    2.709341         Assists\n",
              "19    2.214543          Errors"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>VIF Factor</th>\n",
              "      <th>variable</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21.762082</td>\n",
              "      <td>Intercept</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.134115</td>\n",
              "      <td>League[T.N]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.075398</td>\n",
              "      <td>Division[T.W]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.099063</td>\n",
              "      <td>NewLeague[T.N]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.944366</td>\n",
              "      <td>AtBat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>30.281255</td>\n",
              "      <td>Hits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>7.758668</td>\n",
              "      <td>HmRun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>15.246418</td>\n",
              "      <td>Runs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>11.921715</td>\n",
              "      <td>RBI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>4.148712</td>\n",
              "      <td>Walks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9.313280</td>\n",
              "      <td>Years</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>251.561160</td>\n",
              "      <td>CAtBat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>502.954289</td>\n",
              "      <td>CHits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>46.488462</td>\n",
              "      <td>CHmRun</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>162.520810</td>\n",
              "      <td>CRuns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>131.965858</td>\n",
              "      <td>CRBI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>19.744105</td>\n",
              "      <td>CWalks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1.236317</td>\n",
              "      <td>PutOuts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>2.709341</td>\n",
              "      <td>Assists</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>2.214543</td>\n",
              "      <td>Errors</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Oyw42sVvXlK",
        "outputId": "531b9260-59d6-4d0a-c3ea-3361640278d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "##In R\n",
        "##Read in data and load libraries\n",
        "library(MASS)\n",
        "#library(ISLR)\n",
        "#library(boot)\n",
        "library(car)\n",
        "hitters <- read.csv(file = \"hitters.csv\", header = T)\n",
        "n <- dim(hitters)[1]\n",
        "\n",
        "##a\n",
        "mod <- lm('Salary ~ .', data = hitters)\n",
        "vif(mod)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in library(car) : there is no package called ‘car’\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in library(car) : there is no package called ‘car’\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgXnuYEVvXlN"
      },
      "source": [
        "Multicollinearity does appear to be an issue. We typically point out variables with VIF >5 or so, and there are several variables in this data set with larger VIF than 5 or even 10. The three variables with the largest VIFs are Career Hits ($CHits = 502.954$), Career At Bats ($CAtBat = 251.56116$), and Career Runs ($CRuns = 162.5208$). It's not really surprising that these are all very high, because they are likely dependent upon one another. A player can't have a lot of hits if he doesn't have very many at bats, and hits mean the player gets on base, which increases the chances that he will score."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZduNzTyvXlO",
        "outputId": "2e275076-a1d8-4a48-89a9-9e363a0b347f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "##b\n",
        "library(leaps)\n",
        "all_poss <- regsubsets(Salary ~ ., data = hitters, nvmax = 19)\n",
        "all_poss_summ <- summary(all_poss)\n",
        "all_poss_summ"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in library(leaps) : there is no package called ‘leaps’\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in library(leaps) : there is no package called ‘leaps’\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rX-GH_1VvXlR",
        "outputId": "c43e275a-340c-4427-a25f-d822413d9331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "%%R\n",
        "max_idx <- which.max(all_poss_summ$adjr2)\n",
        "max_idx"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in which.max(all_poss_summ$adjr2) : \n",
            "  object 'all_poss_summ' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in which.max(all_poss_summ$adjr2) : \n",
            "  object 'all_poss_summ' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNBrFxK-vXlU",
        "outputId": "7099b897-d402-4755-cdc8-ab7374c79dfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "%%R\n",
        "plot(all_poss_summ$adjr2, type = \"l\", xlab = \"Number of Explanatory Variables\", ylab = bquote(\"Adjusted R\"^2), main = \"Optimal Number of Explanatory Variables\")\n",
        "points(all_poss_summ$adjr2, pch = 16)\n",
        "points(x = max_idx, y = all_poss_summ$adjr2[max_idx], pch = 16, col = \"red\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in plot(all_poss_summ$adjr2, type = \"l\", xlab = \"Number of Explanatory Variables\",  : \n",
            "  object 'all_poss_summ' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in plot(all_poss_summ$adjr2, type = \"l\", xlab = \"Number of Explanatory Variables\",  : \n",
            "  object 'all_poss_summ' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LT1jXbZcvXlW",
        "outputId": "c16207d6-373d-4379-b48c-299096ca3899",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "##This tells us we want 11 variables in the model.. so which are they?\n",
        "all_poss_summ$which[max_idx,]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in withVisible({ : object 'all_poss_summ' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in withVisible({ : object 'all_poss_summ' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZuL1R_L1vXlZ"
      },
      "source": [
        "We see here that using 11 explanatory variables gives us the optimal model for this data set. We will want to use the variables AtBat, Hits, Walks, CAtBat, CRuns, CRBI, CWalks, League, Division, PutOuts, and Assists.\n",
        "\n",
        "For each possible number of explanatory variables (in this case, for 0 explanatory variables up to all 19), All Possible Regressions fits every possible model (determined by the unique combinations of $x_i$'s) and decides which new variable in each number category (as the number increases) is the most significant and therefore most important to include in the model for that specific number of variables. For all of these models, R stores the selection criteria BIC, $R_{adj}^2$, and $C_p$ (which we haven't talked about but is in the book). Then, the user picks one of those and selects the optimal number of variables according to that selection criterion. For example, in what I did above, I used $R_{adj}^2$ and had R tell me what number of variables had the highest $R_{adj}^2$ and which of those variables gave me that $R_{adj}^2$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClqsnzfgvXlZ",
        "outputId": "786bd4f9-e4fb-438c-c37e-9d077c489f3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "##c\n",
        "library(MASS)\n",
        "smallest <- lm(Salary ~ 1, data = hitters)\n",
        "largest <- lm(Salary ~ ., data = hitters)\n",
        "\n",
        "# Forward Selection\n",
        "stepAIC(object = smallest, scope = list(upper = largest, lower = smallest), direction = \"forward\")\n",
        "mod_forward <- stepAIC(object = smallest, scope = list(upper = largest, lower = smallest), direction = \"forward\", trace = 0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in is.data.frame(data) : object 'hitters' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in is.data.frame(data) : object 'hitters' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHTjv2LFvXlj",
        "outputId": "6e3d3a73-1b9b-489f-929b-ae56f448928f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "summary(mod_forward)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in summary(mod_forward) : object 'mod_forward' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in summary(mod_forward) : object 'mod_forward' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGQaKWrgvXlm"
      },
      "source": [
        "Using forward selection, R identified the best model as the one with the 10 variables AtBat, Hits, Walks, CAtBat, CRuns, CRBI, CWalks, PutOuts, Assists, and Division.\n",
        "\n",
        "Forward selection begins by fitting the smallest model possible-- the one with no variables (intercept only). Calculate its AIC. Then, we calculate the AIC for each of the 1 variable models; if the AIC for a 1 variable model is smaller than that of the intercept only model, then we add the 1 variable model with the smallerst AIC. Otherwise, we stick with the current intercept only model. Next, we consider the 2 variable models that have our first chosen variable as one of the two. If the AIC would improve by adding another variable to the model (as indicated by a smaller AIC), then we add the variable that shrinks the AIC the most. Otherwise, we stick with the 1 variable model. This continues until we reach a point where either a) there are no variables we could add that would improve/reduce the AIC or b) we have added all variables to the model. \n",
        "\n",
        "So in this specific case, we started with an AIC of 3215.77 and first added CRBI (which reduced the AIC to 3115.8), then Hits (reducing AIC to 3074.1), then PutOuts, etc. up until after we added Assists, which is when the AIC reached a value (3031.26) that would not be reduced upon adding any of the remaining variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmhWMYUxvXln",
        "outputId": "33c84340-c711-4986-ff0b-3567abdaece7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "#d\n",
        "# Backward elimination\n",
        "stepAIC(object = largest, scope = list(upper = largest, lower = smallest), direction = \"backward\")\n",
        "mod_backward <- stepAIC(object = largest, scope = list(upper = largest, lower = smallest), direction = \"backward\", trace = 0)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in terms(object) : object 'largest' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in terms(object) : object 'largest' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv2t1YtnvXlp",
        "outputId": "13518fde-4158-4984-8fc5-435d9419dcf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "summary(mod_backward)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in summary(mod_backward) : object 'mod_backward' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in summary(mod_backward) : object 'mod_backward' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vlmUNkf6vXlr"
      },
      "source": [
        "With backward elimination, the model with the 10 variables AtBat, Hits, Walks, CAtBat, CRuns, CRBI, CWalks, PutOuts, Assists, and Division was also deemed the best model.\n",
        "\n",
        "In backward elimination, we begin by fitting the largest model possible-- the full model. Calculate its AIC. Then, we calculate the AIC for each of the $n-1 = 18$ variable models; if the AIC for an 18 variable model is smaller than that of the full model, then we take the 18 variable model without the variable that, upon removal, lowers the AIC the most. Otherwise, we stick with the current full model. Next, we consider the $n-2 = 17$ variable models that have our first chosen variable as one of the two. If the AIC would decrease by dropping another variable to the model, then we drop the variable that shrinks the AIC the most. Otherwise, we stick with the 18 variable model. This continues until we reach a model where either a) there are no variables we could remove that would improve/reduce the AIC or b) we have eliminated all variables from the model. \n",
        "\n",
        "So in this specific case, we started with an AIC of 3046.02 and first dropped CHmRun (which reduced the AIC to 3044.03), then dropped Years (reducing AIC to 3042.1), then New League, etc. up until after we eliminated League, which is when the AIC reached a value (3031.26) that would not be reduced upon getting rid any of the remaining variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ye-Ttl8LvXls",
        "outputId": "7d89a6a7-a7ac-42e9-f3a4-1e16832225fc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "#e\n",
        "# Hybrid\n",
        "stepAIC(object = smallest, scope = list(upper = largest, lower = smallest), direction = \"both\")\n",
        "mod_hybrid <- stepAIC(object = smallest, scope = list(upper = largest, lower = smallest), direction = \"both\", trace = 0)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in terms(object) : object 'smallest' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in terms(object) : object 'smallest' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaP_ayiJvXlu",
        "outputId": "bd0f975c-e2ba-45ef-9ecc-673866cd9c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "summary(mod_hybrid)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in summary(mod_hybrid) : object 'mod_hybrid' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in summary(mod_hybrid) : object 'mod_hybrid' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_eZW7ivvXlx"
      },
      "source": [
        "As with the previous two stepwise selection techniques, hybrid selection decided the model with the 10 variables AtBat, Hits, Walks, CAtBat, CRuns, CRBI, CWalks, PutOuts, Assists, and Division was the best.\n",
        "\n",
        "Hybrid selection begins as Forward Selection does-- by fitting the intercept only model, calculating the AIC, and considering all 1 variable models. If the AIC for a 1 variable model is smaller than that of the intercept only model, then we take the 1 variable model with the variable for which the AIC will be the smallest. Otherwise, we stick with the intercept only model. Next, we consider all 2 variable models that have our first chosen variable as one of the two. If the AIC would improve by adding another variable to the model (as indicated by a smaller AIC), then we add the variable that shrinks the AIC the most. Otherwise, we stick with the 1 variable model. (R also considers dropping the first variable, which is redundant, as if this would lower AIC, we would not have added the variable in the first place.) Then, we consider all 3 variable models with the first two chosen variables and an additional one. If the AIC would decrease with another variable added, then we take that three variable model with the smallest AIC. At this step and for the remaining steps, R considers the AICs for all models with one additional variable and one fewer variable (taking all combinations). This allows for the possibility of getting rid of a variable that would be important if we were going to stick to a fixed, small-variable model but may not be important as other variable interactions are added to the model. This continues until we reach a point where  there are no variables we could add or drop that would improve/reduce the AIC.\n",
        "\n",
        "So in this specific case, we again started with an AIC of 3215.77 and first added CRBI (which reduced the AIC to 3115.8), then Hits (reducing AIC to 3074.1), then PutOuts, etc. up until after we added Assists, which is when the AIC reached a value (3031.26) that would not be reduced upon adding any of the remaining variables. Note that in this selection, we did not ever need to eliminate a variable, but at each step, R did consider what the resulting AIC would be if one of the current variables was dropped (this is indicated by the - sign in the stepAIC table printout)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ6z8MEfvXlx",
        "outputId": "8d072e64-5335-4f14-b0be-69b49f224384",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "##f\n",
        "y = hitters['Salary']\n",
        "X = hitters.drop(['Salary', 'League', 'Division', 'NewLeague'], axis = 1)\n",
        "league = pd.get_dummies(hitters['League'])\n",
        "division = pd.get_dummies(hitters['Division'])\n",
        "new_league = pd.get_dummies(hitters['NewLeague'])\n",
        "X = pd.concat([X, league['A'], division['E'], new_league['A']], axis = 1)\n",
        "X.columns = ['AtBat', 'Hits', 'HmRun', 'Runs', 'RBI', 'Walks', 'Years', 'CAtBat', 'CHits', 'CHmRun', 'CRuns', 'CRBI', 'CWalks', 'PutOuts', 'Assists', 'Errors', 'League', 'Division', 'NewLeague']\n",
        "\n",
        "## Cross Validation\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
        "train = pd.concat([X_train, y_train], axis = 1)\n",
        "\n",
        "mod_full = smf.ols('Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + PutOuts + Assists + Errors + League + Division + NewLeague', data = train).fit()\n",
        "pred_full = mod_full.predict(X_test)\n",
        "RMSE1_full = np.sqrt(np.mean((y_test - pred_full)**2))\n",
        "RMSE1_full"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "374.1016115572486"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDF0hGHQvXl1",
        "outputId": "9a7f2d3e-b5ef-4391-c719-dade8d86d094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m_optim = smf.ols('Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + PutOuts + Assists + League + Division', data = train).fit()\n",
        "pred_optim = m_optim.predict(X_test)\n",
        "RMSE2_optim = np.sqrt(np.mean((y_test - pred_optim)**2))\n",
        "RMSE2_optim"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "368.37302173645344"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSDLBLmcvXl3",
        "outputId": "68d5f33d-9696-4b0f-b307-aae67bd38167",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "m_best_step = smf.ols('Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + PutOuts + Assists + Division', data = train).fit()\n",
        "pred_best_step = m_best_step.predict(X_test)\n",
        "RMSE_best_step = np.sqrt(np.mean((y_test - pred_best_step)**2))\n",
        "RMSE_best_step"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "365.15407981074935"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UMwTXcDzvXl6"
      },
      "source": [
        "***Note here that I did not need to find the BIC myself. Prof. Stevens told us what those variables were, but my calculations are confirmation, I guess :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3OdR_ADBvXl6",
        "outputId": "e1c02abb-43ab-4a5c-844c-e21cd7a9aae8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "##We must use R with the bic on all poss summ\n",
        "##we want to minimize the -logL\n",
        "min_idxBIC <- which.min(all_poss_summ$bic)\n",
        "min_idxBIC"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in which.min(all_poss_summ$bic) : object 'all_poss_summ' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in which.min(all_poss_summ$bic) : object 'all_poss_summ' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHEhwZQnvXl9",
        "outputId": "aa70b54e-a541-4554-aef3-03a33b395a3c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "%%R\n",
        "plot(all_poss_summ$bic, type = \"l\", xlab = \"Number of Explanatory Variables\", ylab = bquote(\"BIC\"), main = \"Optimal Number of Explanatory Variables\")\n",
        "points(all_poss_summ$bic, pch = 16)\n",
        "points(x = min_idxBIC, y = all_poss_summ$bic[min_idxBIC], pch = 16, col = \"red\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in plot(all_poss_summ$bic, type = \"l\", xlab = \"Number of Explanatory Variables\",  : \n",
            "  object 'all_poss_summ' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in plot(all_poss_summ$bic, type = \"l\", xlab = \"Number of Explanatory Variables\",  : \n",
            "  object 'all_poss_summ' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTQ9sVL3vXmA",
        "outputId": "d5da78c2-ad57-4e9a-af93-19959552feb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%R\n",
        "##This tells us we want the following 6 variables in the model\n",
        "all_poss_summ$which[min_idxBIC,]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in withVisible({ : object 'all_poss_summ' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2G2RieRDvXmD"
      },
      "source": [
        "It looks like AtBat, Hits, Walks, CRBI, Division, and PutOuts are the variables we should have in the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-kPf-SLvXmD",
        "outputId": "d0fa416b-dd0d-42df-e5c2-aa8d3ff8e51b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "### \n",
        "m_best_BIC = smf.ols('Salary ~ AtBat + Hits + Walks + CRBI + PutOuts + Division', data = train).fit()\n",
        "pred_best_BIC = m_best_BIC.predict(X_test)\n",
        "RMSE3_best_BIC = np.sqrt(np.mean((y_test - pred_best_BIC)**2))\n",
        "RMSE3_best_BIC"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "357.8142643379224"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaPEXBK5vXmF",
        "outputId": "28f95e80-c07d-420a-d328-4a43a311f041",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "##part f\n",
        "library(ISLR)\n",
        "trn <- sample(x = c(rep(TRUE, round(0.8 * n)), rep(FALSE, n-round(0.8*n))), size = n, replace = FALSE)\n",
        "train <- hitters[trn,]\n",
        "tst <- !trn \n",
        "test <- hitters[tst,]\n",
        "\n",
        "mFull <- lm(Salary ~ ., data = train)\n",
        "predFull <- predict(object = mFull, newdata = test)\n",
        "RMSEFull <- sqrt(mean((test$Salary - predFull)^2))\n",
        "RMSEFull"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in library(ISLR) : there is no package called ‘ISLR’\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in library(ISLR) : there is no package called ‘ISLR’\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UI84V13RvXmI",
        "outputId": "a15983a6-ae64-4235-a202-7e39388b8339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "%%R\n",
        "\n",
        "mOptim <- lm(Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + PutOuts + Assists + Division + League, data = train)\n",
        "predOptim <- predict(object = mOptim, newdata = test)\n",
        "RMSEOptim <- sqrt(mean((test$Salary - predOptim)^2))\n",
        "RMSEOptim"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in is.data.frame(data) : object 'train' not found\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/rpy2/rinterface/__init__.py:186: RRuntimeWarning: Error in is.data.frame(data) : object 'train' not found\n",
            "\n",
            "  warnings.warn(x, RRuntimeWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mQ01wtiNvXmK",
        "outputId": "d43ea00a-0049-43b8-8fbe-a688e2f0c0b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%R\n",
        "\n",
        "mStep <- lm(Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + PutOuts + Assists + Division, data = train)\n",
        "predStep <- predict(object = mStep, newdata = test)\n",
        "RMSEStep <- sqrt(mean((test$Salary - predStep)^2))\n",
        "RMSEStep"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in is.data.frame(data) : object 'train' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NYqa3-eUvXmN",
        "outputId": "5f610c9e-c136-419b-94f1-606f0841f764",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%R\n",
        "\n",
        "mBIC <- lm(Salary ~ AtBat + Hits + Walks + CRBI + PutOuts + Division, data = train)\n",
        "predBIC <- predict(object = mBIC, newdata = test)\n",
        "RMSEBIC <- sqrt(mean((test$Salary - predBIC)^2))\n",
        "RMSEBIC"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in is.data.frame(data) : object 'train' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9-NxHyxvXmQ"
      },
      "source": [
        "It's honestly really hard to tell which is the best using plain cross validation. The full model is always the worst, but the other three seem to take turns having the lowest RMSE. The values fluctuate pretty wildly with different random sets of train and test (from 210 ish to 400 some), and there is not one model that consistently has the lowest RMSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nW2-p2VvXmQ",
        "outputId": "039261ef-825a-4a16-9e6d-c2049098b39f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#g\n",
        "## K-fold Cross Validation\n",
        "#full\n",
        "numfolds = 10\n",
        "kf = KFold(n_splits=numfolds, shuffle = True)\n",
        "MSE = 0\n",
        "for train_indices, test_indices in kf.split(X):\n",
        "    train_X = X.iloc[train_indices, :]; train_y = y[train_indices]\n",
        "    test_X = X.iloc[test_indices, :]; test_y = y[test_indices]\n",
        "    training = pd.concat([train_X, train_y], axis = 1)\n",
        "    m = smf.ols('Salary ~ AtBat + Hits + HmRun + Runs + RBI + Walks + Years + CAtBat + CHits + CHmRun + CRuns + CRBI + CWalks + PutOuts + Assists + Errors + League + Division + NewLeague', data = training).fit()   \n",
        "    pred = m.predict(test_X)\n",
        "    MSE = MSE + np.mean((test_y - pred)**2)\n",
        "RMSE1 = np.sqrt(MSE/numfolds)\n",
        "RMSE1"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "358.0409538503632"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oaqK2DQvXmU",
        "outputId": "136024ce-9f5c-44b6-c760-549b52b58bec",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#optim\n",
        "numfolds = 10\n",
        "kf = KFold(n_splits=numfolds, shuffle = True)\n",
        "MSE = 0\n",
        "for train_indices, test_indices in kf.split(X):\n",
        "    train_X = X.iloc[train_indices, :]; train_y = y[train_indices]\n",
        "    test_X = X.iloc[test_indices, :]; test_y = y[test_indices]\n",
        "    training = pd.concat([train_X, train_y], axis = 1)\n",
        "    m = smf.ols('Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + PutOuts + Assists + Division + League', data = training).fit()   \n",
        "    pred = m.predict(test_X)\n",
        "    MSE = MSE + np.mean((test_y - pred)**2)\n",
        "RMSE2 = np.sqrt(MSE/numfolds)\n",
        "RMSE2"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "327.48898106270093"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WvmwaQ0mvXmY",
        "outputId": "b2edda5f-fab9-4171-eae4-c628ed6b5f07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#step\n",
        "numfolds = 10\n",
        "kf = KFold(n_splits=numfolds, shuffle = True)\n",
        "MSE = 0\n",
        "for train_indices, test_indices in kf.split(X):\n",
        "    train_X = X.ix[train_indices, :]; train_y = y[train_indices]\n",
        "    test_X = X.ix[test_indices, :]; test_y = y[test_indices]\n",
        "    training = pd.concat([train_X, train_y], axis = 1)\n",
        "    m = smf.ols('Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + PutOuts + Assists + Division', data = training).fit()   \n",
        "    pred = m.predict(test_X)\n",
        "    MSE = MSE + np.mean((test_y - pred)**2)\n",
        "RMSE3 = np.sqrt(MSE/numfolds)\n",
        "RMSE3"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
            ".ix is deprecated. Please use\n",
            ".loc for label based indexing or\n",
            ".iloc for positional indexing\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
            "  \n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
            ".ix is deprecated. Please use\n",
            ".loc for label based indexing or\n",
            ".iloc for positional indexing\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "328.95724975404283"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bBRTqyFvXmc",
        "outputId": "fb1850f4-5f0f-43d0-df3e-8b3ddc249cfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "#bic\n",
        "numfolds = 10\n",
        "kf = KFold(n_splits=numfolds, shuffle = True)\n",
        "MSE = 0\n",
        "for train_indices, test_indices in kf.split(X):\n",
        "    train_X = X.ix[train_indices, :]; train_y = y[train_indices]\n",
        "    test_X = X.ix[test_indices, :]; test_y = y[test_indices]\n",
        "    training = pd.concat([train_X, train_y], axis = 1)\n",
        "    m = smf.ols('Salary ~ AtBat + Hits + Walks + CRBI + PutOuts + Division', data = training).fit()   \n",
        "    pred = m.predict(test_X)\n",
        "    MSE = MSE + np.mean((test_y - pred)**2)\n",
        "RMSE4 = np.sqrt(MSE/numfolds)\n",
        "RMSE4"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:6: DeprecationWarning: \n",
            ".ix is deprecated. Please use\n",
            ".loc for label based indexing or\n",
            ".iloc for positional indexing\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
            "  \n",
            "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:7: DeprecationWarning: \n",
            ".ix is deprecated. Please use\n",
            ".loc for label based indexing or\n",
            ".iloc for positional indexing\n",
            "\n",
            "See the documentation here:\n",
            "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
            "  import sys\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "334.16342071770106"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ1FQ8H5vXme",
        "outputId": "e4a65a5e-5832-4c54-a150-28e4a14662f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%R\n",
        "\n",
        "#g\n",
        "## K-fold Cross-Validation\n",
        "#full\n",
        "library(boot)\n",
        "m1 <- glm(Salary ~ ., data = hitters)\n",
        "RMSE1 <- sqrt((cv.glm(hitters, m1, K = 10)$delta)[1])\n",
        "RMSE1"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in is.data.frame(data) : object 'hitters' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zc-NTV6HvXmg",
        "outputId": "ed064f42-99e9-4ccd-a0fc-2fcce4b09e51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%R\n",
        "#optim\n",
        "m2 <- glm(Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + PutOuts + Assists + Division + League, data = hitters)\n",
        "RMSE2 <- sqrt((cv.glm(hitters, m2, K = 10)$delta)[1])\n",
        "RMSE2"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in is.data.frame(data) : object 'hitters' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ47ljQtvXmj",
        "outputId": "1f3e750f-8a3c-4f3d-fb63-401e19483186",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%R\n",
        "#step\n",
        "m3 <- glm(Salary ~ AtBat + Hits + Walks + CAtBat + CRuns + CRBI + CWalks + PutOuts + Assists + Division, data = hitters)\n",
        "RMSE3 <- sqrt((cv.glm(hitters, m3, K = 10)$delta)[1])\n",
        "RMSE3"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in is.data.frame(data) : object 'hitters' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cybo2hoOvXml",
        "outputId": "ae26403d-4151-4dee-a933-add81ff1598d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "%%R\n",
        "#bic\n",
        "m4 <- glm(Salary ~ AtBat + Hits + Walks + CRBI + PutOuts + Division, data = hitters)\n",
        "RMSE4 <- sqrt((cv.glm(hitters, m4, K = 10)$delta)[1])\n",
        "RMSE4"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Error in is.data.frame(data) : object 'hitters' not found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHos6EwPvXmn"
      },
      "source": [
        "Stepwise Selection Model appears to be the best. The K-Fold Validation method shows the Stepwise RMSE as about 0.5 (for an average random generation of training/test sets) less than that of the Optimal model. Since RMSE is a measure of how close the observed values are to the model's predicted values, a low RMSE indicates the model will have a good predictive accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W_VdD1DVvXmo"
      },
      "source": [
        "h)\n",
        "\n",
        "K-Fold Validation is much more reliable than Cross Validation (due to the potentially large variability of the latter), and it actually gives us consistent evidence that Stepwise Selection Model is the best choice for us to use. The K-fold validation estimates of RMSE are more stable since we take multiple measurements of the MSE and average them, so we can trust K-fold more and believe they more accurately depict the predictive accuracy of the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3JodNkXvXmo"
      },
      "source": [
        "i)\n",
        "\n",
        "I would probably want to use the Stepwise Selection Model if I were going for predictive accuracy. Even though SS Model has fewer variables than Optim Model, the one additional variable in Optim (League) must not be important enough to actually make a difference in the predictive accuracy. Also, the Stepwise Selection process showed that adding League to the model would raise the AIC; AIC quantifies the goodness of fit of the model while penalizing unneeded complexity, so the lower AIC of the SS Model (without League) as compared to the higher AIC of the model with League (Optim) tells us that adding League is more of a burden than a help in terms of simplicity and calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8y_z1lN8vXmo"
      },
      "source": [
        ""
      ],
      "execution_count": 31,
      "outputs": []
    }
  ]
}
